library(ISLR)
library(dplyr)
library(AppliedPredictiveModeling)
library(class)
setwd("C:/Users/Glauton/Dropbox/Glauton/UFC/6-Sexto Semestre/ICA/homeworks/homework3")
load("grantData_HW3.RData")
# o comando acima nos permite usar dois conjuntos de dados, um de treinamento e um de teste, facilitando o processo, ja que nao e necessario dividir
# conjuntos: training e testing
# vamos verificar a variancia de algumas variaveis preditoras para saber se ha necessidade de colocar os
# dados numa mesma escala, para obtermos um algoritmo mais performatico
var(training[,1])
# => 1.016723
var(training[,2])
# => 0.03638266
var(training[,3])
# => 0.8112048
var(training[,4])
# => 0.0006102024
var(training[,5])
# => 0.003409142
# aqui nao pegamos a ultima variavel pois ela corresponde a 'successfull' e 'unsuccessfull'
new_training <- scale(training[,1:1881])
# vamos repetir esses passos para o s dados de teste tambem
var(testing[,1])
# => 1.271028
var(testing[,2])
# => 0.02634743
var(testing[,3])
# => 0.8651225
var(testing[,4])
# => 0
var(testing[,5])
# => 0.005769102
# aqui repetimos o mesmo processo dos dados de treinamento
new_testing <- scale(testing[,1:1881])
# para testar ambos os conjuntos, vamos verificar a variancia de uma variavel preditiva aleatoria em cada um
var(new_training[,3])
var(new_testing[,5])
# vamos comecar com um K (numero de vizinhos) igual a 1
set.seed(1)
previsoes <- knn(train = training[,-1882], test = testing[,-1882], cl = training[,1882], k = 1)
head(previsoes)
mean(testing[,1882] != previsoes)
previsoes
confusionMatrix(testing, testing[,1882], positive = NULL,
dnn = c("successfull", "unsuccessfull"), prevalence = NULL,
mode = "sens_spec")
table(testing, testing[, 1882])
table(new_testing, testing[, 1882])
table(testing[.-1882], testing[, 1882])
table(new_testing[.-1882], testing[, 1882])
table(new_testing[,-1882], testing[, 1882])
table(previsoes, testing[,-1882])
table(previsoes, testing[,-1882])
table(previsoes, testing[,-1881])
table(previsoes, new_testing)
table(previsoes, testing[,1882])
